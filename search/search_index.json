{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>Distributask is a simple way to distribute rendering tasks across multiple machines.</p> <p>This documentation is intended to help you understand the structure of the Distributask API and codebase and how to use it to distribute rendering tasks across multiple machines for your own projects.</p>"},{"location":"#core-use-cases","title":"Core Use Cases","text":"<p>Distributask can be used for any task that can is parallelizable. Some specific use cases include:</p> <ul> <li>Rendering videos</li> <li>Running simulations</li> <li>Generating or processing large datasets</li> </ul>"},{"location":"#getting-started","title":"Getting Started","text":"<p>Visit the Getting Started page to learn how to set up your environment and get started with distributing with Distributask.</p>"},{"location":"#overview","title":"Overview","text":"<p>Distributed rendering using Distributask can be broken into four steps:</p>"},{"location":"#creating-the-task-queue","title":"Creating the task queue","text":"<p>Distributask uses Celery, an asyncronous distributed task processing package, to create the task queue on your local machine. Each task on the queue is a function that tells remote machines, or workers, what to do. For example, if we wanted to render videos, each task would be a function that contains the code to render a different video.</p>"},{"location":"#passing-the-tasks-to-workers","title":"Passing the tasks to workers","text":"<p>Distributask uses Redis, a data structure that can be used as a database, as a message broker. This means that Redis is used to transfer tasks yet to be done from the task queue to the worker so that the job can be done.</p>"},{"location":"#executing-the-tasks","title":"Executing the tasks","text":"<p>Distributask uses Vast.ai, a decentralized GPU market, to create workers that execute the task. The task is given to the worker, executed, and the completed task status is passed back to the central machine via Redis.</p>"},{"location":"#storing-results-of-the-tasks","title":"Storing results of the tasks","text":"<p>Distributask uses Huggingface, a platform for sharing AI models and datasets, to store the results of the task. The results of the task are uploaded to Hugginface using API calls in Distributask. For example, our rendered videos would be uploaded as a dataset on Huggingface.</p>"},{"location":"#flowchart-of-distributask-process","title":"Flowchart of Distributask process","text":""},{"location":"distributask/","title":"Distributask Class","text":""},{"location":"distributask/#distributask.Distributask","title":"<code>distributask.Distributask</code>","text":"<p>The Distributask class contains the core features of distributask, including creating and executing the task queue, managing workers using the Vast.ai API, and uploading files and directories using the Hugging Face API.</p> Source code in <code>distributask/distributask.py</code> <pre><code>class Distributask:\n    \"\"\"\n    The Distributask class contains the core features of distributask, including creating and\n    executing the task queue, managing workers using the Vast.ai API, and uploading files and directories\n    using the Hugging Face API.\n    \"\"\"\n\n    app: Celery = None\n    redis_client: Redis = None\n    registered_functions: dict = {}\n    pool: ConnectionPool = None\n\n    def __init__(\n        self,\n        hf_repo_id=os.getenv(\"HF_REPO_ID\"),\n        hf_token=os.getenv(\"HF_TOKEN\"),\n        vast_api_key=os.getenv(\"VAST_API_KEY\"),\n        redis_host=os.getenv(\"REDIS_HOST\", \"localhost\"),\n        redis_password=os.getenv(\"REDIS_PASSWORD\", \"\"),\n        redis_port=os.getenv(\"REDIS_PORT\", 6379),\n        redis_username=os.getenv(\"REDIS_USER\", \"default\"),\n        broker_pool_limit=os.getenv(\"BROKER_POOL_LIMIT\", 1),\n    ) -&gt; None:\n        \"\"\"\n        Initialize the Distributask object with the provided configuration parameters. Also sets some\n        default settings in Celery and handles cleanup of Celery queue and Redis server on exit.\n\n        Args:\n            hf_repo_id (str): Hugging Face repository ID.\n            hf_token (str): Hugging Face API token.\n            vast_api_key (str): Vast.ai API key.\n            redis_host (str): Redis host. Defaults to \"localhost\".\n            redis_password (str): Redis password. Defaults to an empty string.\n            redis_port (int): Redis port. Defaults to 6379.\n            redis_username (str): Redis username. Defaults to \"default\".\n            broker_pool_limit (int): Celery broker pool limit. Defaults to 1.\n\n        Raises:\n            ValueError: If any of the required parameters (hf_repo_id, hf_token, vast_api_key) are not provided.\n        \"\"\"\n        if hf_repo_id is None:\n            raise ValueError(\n                \"HF_REPO_ID is not provided to the Distributask constructor\"\n            )\n\n        if hf_token is None:\n            raise ValueError(\"HF_TOKEN is not provided to the Distributask constructor\")\n\n        if vast_api_key is None:\n            raise ValueError(\n                \"VAST_API_KEY is not provided to the Distributask constructor\"\n            )\n\n        if redis_host == \"localhost\":\n            print(\n                \"WARNING: Using default Redis host 'localhost'. This is not recommended for production use and won't work for distributed rendering.\"\n            )\n\n        self.settings = {\n            \"HF_REPO_ID\": hf_repo_id,\n            \"HF_TOKEN\": hf_token,\n            \"VAST_API_KEY\": vast_api_key,\n            \"REDIS_HOST\": redis_host,\n            \"REDIS_PASSWORD\": redis_password,\n            \"REDIS_PORT\": redis_port,\n            \"REDIS_USER\": redis_username,\n            \"BROKER_POOL_LIMIT\": broker_pool_limit,\n        }\n\n        redis_url = self.get_redis_url()\n        # start Celery app instance\n        self.app = Celery(\"distributask\", broker=redis_url, backend=redis_url)\n        self.app.conf.broker_pool_limit = self.settings[\"BROKER_POOL_LIMIT\"]\n\n        def cleanup_redis():\n            \"\"\"\n            Deletes keys in redis related to Celery tasks and closes the Redis connection on exit\n            \"\"\"\n            patterns = [\"celery-task*\", \"task_status*\"]\n            redis_connection = self.get_redis_connection()\n            for pattern in patterns:\n                for key in redis_connection.scan_iter(match=pattern):\n                    redis_connection.delete(key)\n            print(\"Redis server cleared\")\n\n        def cleanup_celery():\n            \"\"\"\n            Clears Celery task queue on exit\n            \"\"\"\n            self.app.control.purge()\n            print(\"Celery queue cleared\")\n\n        # At exit, close Celery instance, delete all previous task info from queue and Redis, and close Redis\n        atexit.register(self.app.close)\n        atexit.register(cleanup_redis)\n        atexit.register(cleanup_celery)\n\n        self.redis_client = self.get_redis_connection()\n\n        # Tasks are acknowledged after they have been executed\n        self.app.conf.task_acks_late = True\n        self.call_function_task = self.app.task(\n            bind=True, name=\"call_function_task\", max_retries=3, default_retry_delay=30\n        )(self.call_function_task)\n\n    def __del__(self):\n        \"\"\"Destructor to clean up resources.\"\"\"\n        if self.pool is not None:\n            self.pool.disconnect()\n        if self.redis_client is not None:\n            self.redis_client.close()\n        if self.app is not None:\n            self.app.close()\n\n    def log(self, message: str, level: str = \"info\") -&gt; None:\n        \"\"\"\n        Log a message with the specified level.\n\n        Args:\n            message (str): The message to log.\n            level (str): The logging level. Defaults to \"info\".\n        \"\"\"\n        logger = get_task_logger(__name__)\n        getattr(logger, level)(message)\n\n    def get_settings(self) -&gt; str:\n        \"\"\"\n        Return settings of distributask instance.\n        \"\"\"\n        return self.settings\n\n    def get_redis_url(self) -&gt; str:\n        \"\"\"\n        Construct a Redis URL from the configuration settings.\n\n        Returns:\n            str: A Redis URL string.\n\n        Raises:\n            ValueError: If any required Redis connection parameter is missing.\n        \"\"\"\n        host = self.settings[\"REDIS_HOST\"]\n        password = self.settings[\"REDIS_PASSWORD\"]\n        port = self.settings[\"REDIS_PORT\"]\n        username = self.settings[\"REDIS_USER\"]\n\n        if None in [host, password, port, username]:\n            raise ValueError(\"Missing required Redis configuration values\")\n\n        redis_url = f\"redis://{username}:{password}@{host}:{port}\"\n        return redis_url\n\n    def get_redis_connection(self, force_new: bool = False) -&gt; Redis:\n        \"\"\"\n        Returns Redis connection. If it already exists, returns current connection.\n        If it does not exist, its create a new Redis connection using a connection pool.\n\n        Args:\n            force_new (bool): Force the creation of a new connection if set to True. Defaults to False.\n\n        Returns:\n            Redis: A Redis connection object.\n        \"\"\"\n        if self.redis_client is not None and not force_new:\n            return self.redis_client\n        else:\n            self.pool = ConnectionPool(host=self.settings[\"REDIS_HOST\"], \n                                       port=self.settings[\"REDIS_PORT\"],\n                                       password=self.settings[\"REDIS_PASSWORD\"], \n                                       max_connections=1)\n            self.redis_client = Redis(connection_pool=self.pool)\n            atexit.register(self.pool.disconnect)\n\n        return self.redis_client\n\n    def get_env(self, key: str, default: any = None) -&gt; any:\n        \"\"\"\n        Retrieve a value from the configuration or .env file, with an optional default if the key is not found.\n\n        Args:\n            key (str): The key to look for in the settings.\n            default (any): The default value to return if the key is not found. Defaults to None.\n\n        Returns:\n            any: The value from the settings if the key exists, otherwise the default value.\n        \"\"\"\n        return self.settings.get(key, default)\n\n    def call_function_task(self, func_name: str, args_json: str) -&gt; any:\n        \"\"\"\n        Creates Celery task that executes a registered function with provided JSON arguments.\n\n        Args:\n            func_name (str): The name of the registered function to execute.\n            args_json (str): JSON string representation of the arguments for the function.\n\n        Returns:\n            any: Celery.app.task object, represents result of the registered function\n\n        Raises:\n            ValueError: If the function name is not registered.\n            Exception: If an error occurs during the execution of the function. The task will retry in this case.\n        \"\"\"\n        try:\n            if func_name not in self.registered_functions:\n                raise ValueError(f\"Function '{func_name}' is not registered.\")\n\n            func = self.registered_functions[func_name]\n            args = json.loads(args_json)\n            result = func(**args)\n            # self.update_function_status(self.call_function_task.request.id, \"success\")\n\n            return result\n        except Exception as e:\n            self.log(f\"Error in call_function_task: {str(e)}\", \"error\")\n            # self.call_function_task.retry(exc=e)\n\n\n    def register_function(self, func: callable) -&gt; callable:\n        \"\"\"\n        Decorator to register a function so that it can be invoked as a Celery task.\n\n        Args:\n            func (callable): The function to register.\n\n        Returns:\n            callable: The original function, now registered as a callable task.\n        \"\"\"\n        self.registered_functions[func.__name__] = func\n        return func\n\n    def execute_function(self, func_name: str, args: dict) -&gt; Celery.AsyncResult:\n        \"\"\"\n        Execute a registered function as a Celery task with provided arguments.\n\n        Args:\n            func_name (str): The name of the function to execute.\n            args (dict): Arguments to pass to the function.\n\n        Returns:\n            celery.result.AsyncResult: An object representing the asynchronous result of the task.\n        \"\"\"\n        args_json = json.dumps(args)\n        async_result = self.call_function_task.delay(func_name, args_json)\n        return async_result\n\n    def update_function_status(self, task_id: str, status: str) -&gt; None:\n        \"\"\"\n        Update the status of a function task as a new Redis key.\n\n        Args:\n            task_id (str): The ID of the task.\n            status (str): The new status to set.\n        \"\"\"\n        redis_client = self.get_redis_connection()\n        redis_client.set(f\"task_status:{task_id}\", status)\n\n    def initialize_dataset(self, **kwargs) -&gt; None:\n        \"\"\"\n        Initialize a Hugging Face repository if it doesn't exist. Reads Hugging Face info from config or .env\n\n        Args:\n            kwargs: kwargs that can be passed into the HfApi.create_repo function.\n\n        Raises:\n            HTTPError: If repo cannot be created due to connection error other than repo not existing\n        \"\"\"\n        repo_id = self.settings.get(\"HF_REPO_ID\")\n        hf_token = self.settings.get(\"HF_TOKEN\")\n        api = HfApi(token=hf_token)\n\n        # creates new repo if desired repo is not found\n        try:\n            repo_info = api.repo_info(repo_id=repo_id, repo_type=\"dataset\", timeout=30)\n        except HTTPError as e:\n            if e.response.status_code == 404:\n                self.log(\n                    f\"Repository {repo_id} does not exist. Creating a new repository.\",\n                    \"warn\",\n                )\n                api.create_repo(\n                    repo_id=repo_id, token=hf_token, repo_type=\"dataset\", **kwargs\n                )\n            else:\n                raise e\n\n        # Create config.json file\n        config = {\n            \"data_loader_name\": \"custom\",\n            \"data_loader_kwargs\": {\n                \"path\": repo_id,\n                \"format\": \"files\",\n                \"fields\": [\"file_path\", \"text\"],\n            },\n        }\n\n        # apply config.json to created repo\n        with tempfile.TemporaryDirectory() as temp_dir:\n            with Repository(\n                local_dir=temp_dir,\n                clone_from=repo_id,\n                repo_type=\"dataset\",\n                use_auth_token=hf_token,\n            ).commit(commit_message=\"Add config.json\"):\n                with open(os.path.join(temp_dir, \"config.json\"), \"w\") as f:\n                    json.dump(config, f, indent=2)\n\n        self.log(f\"Initialized repository {repo_id}.\")\n\n    # upload a single file to the Hugging Face repository\n    def upload_file(self, file_path: str) -&gt; None:\n        \"\"\"\n        Upload a file to a Hugging Face repository.\n\n        Args:\n            file_path (str): The path of the file to upload.\n\n        Raises:\n            Exception: If an error occurs during the upload process.\n\n        \"\"\"\n        hf_token = self.settings.get(\"HF_TOKEN\")\n        repo_id = self.settings.get(\"HF_REPO_ID\")\n\n        api = HfApi(token=hf_token)\n\n        try:\n            self.log(f\"Uploading {file_path} to Hugging Face repo {repo_id}\")\n            api.upload_file(\n                path_or_fileobj=file_path,\n                path_in_repo=os.path.basename(file_path),\n                repo_id=repo_id,\n                token=hf_token,\n                repo_type=\"dataset\",\n            )\n            self.log(f\"Uploaded {file_path} to Hugging Face repo {repo_id}\")\n        except Exception as e:\n            self.log(\n                f\"Failed to upload {file_path} to Hugging Face repo {repo_id}: {e}\",\n                \"error\",\n            )\n\n    def upload_directory(self, dir_path: str) -&gt; None:\n        \"\"\"\n        Upload a directory to a Hugging Face repository. Can be used to reduce frequency of Hugging Face API\n        calls if you are rate limited while using the upload_file function.\n\n        Args:\n            dir_path (str): The path of the directory to upload.\n\n        Raises:\n            Exception: If an error occurs during the upload process.\n\n        \"\"\"\n        hf_token = self.settings.get(\"HF_TOKEN\")\n        repo_id = self.settings.get(\"HF_REPO_ID\")\n\n        try:\n            self.log(f\"Uploading {dir_path} to Hugging Face repo {repo_id}\")\n\n            api = HfApi(token=hf_token)\n            api.upload_folder(\n                folder_path=dir_path,\n                repo_id=repo_id,\n                repo_type=\"dataset\",\n            )\n            self.log(f\"Uploaded {dir_path} to Hugging Face repo {repo_id}\")\n        except Exception as e:\n            self.log(\n                f\"Failed to upload {dir_path} to Hugging Face repo {repo_id}: {e}\",\n                \"error\",\n            )\n\n    def delete_file(self, repo_id: str, path_in_repo: str) -&gt; None:\n        \"\"\"\n        Delete a file from a Hugging Face repository.\n\n        Args:\n            repo_id (str): The ID of the repository.\n            path_in_repo (str): The path of the file to delete within the repository.\n\n        Raises:\n            Exception: If an error occurs during the deletion process.\n\n        \"\"\"\n        hf_token = self.settings.get(\"HF_TOKEN\")\n        api = HfApi(token=hf_token)\n\n        try:\n            api.delete_file(\n                repo_id=repo_id,\n                path_in_repo=path_in_repo,\n                repo_type=\"dataset\",\n                token=hf_token,\n            )\n            self.log(f\"Deleted {path_in_repo} from Hugging Face repo {repo_id}\")\n        except Exception as e:\n            self.log(\n                f\"Failed to delete {path_in_repo} from Hugging Face repo {repo_id}: {e}\",\n                \"error\",\n            )\n\n    def file_exists(self, repo_id: str, path_in_repo: str) -&gt; bool:\n        \"\"\"\n        Check if a file exists in a Hugging Face repository.\n\n        Args:\n            repo_id (str): The ID of the repository.\n            path_in_repo (str): The path of the file to check within the repository.\n\n        Returns:\n            bool: True if the file exists in the repository, False otherwise.\n\n        Raises:\n            Exception: If an error occurs while checking the existence of the file.\n        \"\"\"\n        hf_token = self.settings.get(\"HF_TOKEN\")\n        api = HfApi(token=hf_token)\n\n        try:\n            repo_files = api.list_repo_files(\n                repo_id=repo_id, repo_type=\"dataset\", token=hf_token\n            )\n            return path_in_repo in repo_files\n        except Exception as e:\n            self.log(\n                f\"Failed to check if {path_in_repo} exists in Hugging Face repo {repo_id}: {e}\",\n                \"error\",\n            )\n            return False\n\n    def list_files(self, repo_id: str) -&gt; list:\n        \"\"\"\n        Get a list of files from a Hugging Face repository.\n\n        Args:\n            repo_id (str): The ID of the repository.\n\n        Returns:\n            list: A list of file paths in the repository.\n\n        Raises:\n            Exception: If an error occurs while retrieving the list of files.\n        \"\"\"\n        hf_token = self.settings.get(\"HF_TOKEN\")\n        api = HfApi(token=hf_token)\n\n        try:\n            repo_files = api.list_repo_files(\n                repo_id=repo_id, repo_type=\"dataset\", token=hf_token\n            )\n            return repo_files\n        except Exception as e:\n            self.log(\n                f\"Failed to get the list of files from Hugging Face repo {repo_id}: {e}\",\n                \"error\",\n            )\n            return []\n\n    def search_offers(self, max_price: float) -&gt; List[Dict]:\n        \"\"\"\n        Search for available offers to rent a node as an instance on the Vast.ai platform.\n\n        Args:\n            max_price (float): The maximum price per hour for the instance.\n\n        Returns:\n            List[Dict]: A list of dictionaries representing the available offers.\n\n        Raises:\n            requests.exceptions.RequestException: If there is an error while making the API request.\n        \"\"\"\n        api_key = self.get_env(\"VAST_API_KEY\")\n        base_url = \"https://console.vast.ai/api/v0/bundles/\"\n        headers = {\n            \"Accept\": \"application/json\",\n            \"Content-Type\": \"application/json\",\n            \"Authorization\": f\"Bearer {api_key}\",\n        }\n        url = (\n            base_url\n            + '?q={\"gpu_ram\":\"&gt;=4\",\"rentable\":{\"eq\":true},\"dph_total\":{\"lte\":'\n            + str(max_price)\n            + '},\"sort_option\":{\"0\":[\"dph_total\",\"asc\"],\"1\":[\"total_flops\",\"asc\"]}}'\n        )\n\n        try:\n            response = requests.get(url, headers=headers)\n            response.raise_for_status()\n            json_response = response.json()\n            return json_response[\"offers\"]\n\n        except requests.exceptions.RequestException as e:\n            self.log(\n                f\"Error: {e}\\nResponse: {response.text if response else 'No response'}\"\n            )\n            raise\n\n    def create_instance(\n        self, offer_id: str, image: str, module_name: str, env_settings: Dict, command: str\n    ) -&gt; Dict:\n        \"\"\"\n        Create an instance on the Vast.ai platform. Passes in some useful Celery settings by default.\n\n        Args:\n            offer_id (str): The ID of the offer to create the instance from.\n            image (str): The image to use for the instance. (example: RaccoonResearch/distributask-test-worker)\n            module_name (str): The name of the module to run on the instance, configured to be a docker file (example: distributask.example.worker)\n            command (str): Command that initializes celery worker. Has default command with specific settings if not passed in. These settings have\n            been found to be beneficial to the stability and simplicity of a Distributask run. \n            env_settings (Dict): Used to pass in environment variables to the Vast.ai instance. This is a dictionary with keys of the \n            environment variable name and values of the desired value of the environment variable.\n\n        Returns:\n            Dict: A dictionary representing the created instance.\n\n        Raises:\n            ValueError: If the Vast.ai API key is not set in the environment.\n            Exception: If there is an error while creating the instance.\n        \"\"\"\n        if self.get_env(\"VAST_API_KEY\") is None:\n            self.log(\"VAST_API_KEY is not set in the environment\", \"error\")\n            raise ValueError(\"VAST_API_KEY is not set in the environment\")\n\n        if command is None:\n            command = f\"celery -A {module_name} worker --loglevel=info --concurrency=1 --without-heartbeat --prefetch-multiplier=1\"\n\n        if env_settings is None:\n            env_settings = self.settings\n\n        json_blob = {\n            \"client_id\": \"me\",\n            \"image\": image,\n            \"env\": env_settings,\n            \"disk\": 32,  # Set a non-zero value for disk\n            \"onstart\": f\"export PATH=$PATH:/ &amp;&amp; cd ../ &amp;&amp; {command}\",\n            \"runtype\": \"ssh ssh_proxy\",\n        }\n        url = f\"https://console.vast.ai/api/v0/asks/{offer_id}/?api_key={self.get_env('VAST_API_KEY')}\"\n        headers = {\"Authorization\": f\"Bearer {self.get_env('VAST_API_KEY')}\"}\n        response = requests.put(url, headers=headers, json=json_blob)\n\n        if response.status_code != 200:\n            self.log(f\"Failed to create instance: {response.text}\", \"error\")\n            raise Exception(f\"Failed to create instance: {response.text}\")\n\n        return response.json()\n\n    def destroy_instance(self, instance_id: str) -&gt; Dict:\n        \"\"\"\n        Destroy an instance on the Vast.ai platform.\n\n        Args:\n            instance_id (str): The ID of the instance to destroy.\n\n        Returns:\n            Dict: A dictionary representing the result of the destroy operation.\n        \"\"\"\n        api_key = self.get_env(\"VAST_API_KEY\")\n        headers = {\"Authorization\": f\"Bearer {api_key}\"}\n        url = (\n            f\"https://console.vast.ai/api/v0/instances/{instance_id}/?api_key={api_key}\"\n        )\n        response = requests.delete(url, headers=headers)\n        return response\n\n    def rent_nodes(\n        self,\n        max_price: float,\n        max_nodes: int,\n        image: str,\n        module_name: str,\n        env_settings: Dict = None,\n        command: str = None,\n    ) -&gt; List[Dict]:\n        \"\"\"\n        Rent nodes as an instance on the Vast.ai platform.\n\n        Args:\n            max_price (float): The maximum price per hour for the nodes.\n            max_nodes (int): The maximum number of nodes to rent.\n            image (str): The image to use for the nodes.\n            module_name (str): The name of the module to run on the nodes.\n\n        Returns:\n            List[Dict]: A list of dictionaries representing the rented nodes. If error is encountered\n            trying to rent, it will retry every 5 seconds.\n        \"\"\"\n        rented_nodes: List[Dict] = []\n        while len(rented_nodes) &lt; max_nodes:\n            search_retries = 10\n            while search_retries &gt; 0:\n                try:\n                    offers = self.search_offers(max_price)\n                    break\n                except Exception as e:\n                    self.log(\n                        f\"Error searching for offers: {str(e)} - retrying in 5 seconds...\",\n                        \"error\",\n                    )\n                    search_retries -= 1\n                    # sleep for 10 seconds before retrying\n                    time.sleep(10)\n                    continue\n\n            offers = sorted(\n                offers, key=lambda offer: offer[\"dph_total\"]\n            )  # Sort offers by price, lowest to highest\n            for offer in offers:\n                time.sleep(5)\n                if len(rented_nodes) &gt;= max_nodes:\n                    break\n                try:\n                    instance = self.create_instance(\n                        offer[\"id\"], image, module_name, env_settings=env_settings, command=command\n                    )\n                    rented_nodes.append(\n                        {\n                            \"offer_id\": offer[\"id\"],\n                            \"instance_id\": instance[\"new_contract\"],\n                        }\n                    )\n                except Exception as e:\n                    self.log(\n                        f\"Error renting node: {str(e)} - searching for new offers\",\n                        \"error\",\n                    )\n                    break  # Break out of the current offer iteration\n            else:\n                # If the loop completes without breaking, all offers have been tried\n                self.log(\"No more offers available - stopping node rental\", \"warning\")\n                break\n\n        atexit.register(self.terminate_nodes, rented_nodes)\n        return rented_nodes\n\n    def get_node_log(self, node: Dict, wait_time: int = 2):\n        \"\"\"\n        Get the log of the Vast.ai instance that is passed in. Makes an api call to tell the instance to send the log,\n        and another one to actually retrive the log\n        Args:\n            node (Dict): the node that corresponds to the Vast.ai instance you want the log from\n            wait_time (int): how long to wait in between the two api calls described above\n\n        Returns:\n            str: the log of the instance requested. If anything else other than a code 200 is received, return None\n        \"\"\"\n        node_id = node[\"instance_id\"]\n        url = f\"https://console.vast.ai/api/v0/instances/request_logs/{node_id}/\"\n\n        payload = {\"tail\": \"1000\"}\n        headers = {\n            \"Accept\": \"application/json\",\n            \"Authorization\": f\"Bearer {self.settings['VAST_API_KEY']}\",\n        }\n\n        response = requests.request(\n            \"PUT\", url, headers=headers, json=payload, timeout=5\n        )\n\n        if response.status_code == 200:\n            log_url = response.json()[\"result_url\"]\n            time.sleep(wait_time)\n            log_response = requests.get(log_url, timeout=5)\n            if log_response.status_code == 200:\n                return log_response\n            else:\n                return None\n        else:\n            return None\n\n    def terminate_nodes(self, nodes: List[Dict]) -&gt; None:\n        \"\"\"\n        Terminate the instances of rented nodes on Vast.ai.\n\n        Args:\n            nodes (List[Dict]): A list of dictionaries representing the rented nodes.\n\n        Raises:\n            Exception: If error in destroying instances.\n        \"\"\"\n        print(\"Terminating nodes...\")\n        for node in nodes:\n            time.sleep(1)\n            try:\n                response = self.destroy_instance(node[\"instance_id\"])\n                if response.status_code != 200:\n                    time.sleep(5)\n                    self.destroy_instance(node[\"instance_id\"])\n            except Exception as e:\n                self.log(\n                    f\"Error terminating node: {node['instance_id']}, {str(e)}\", \"error\"\n                )\n\n    def monitor_tasks(\n        self, tasks, update_interval=1, show_time_left=True, print_statements=True\n    ):\n        \"\"\"\n        Monitor the status of the tasks on the Vast.ai nodes.\n\n        Args:\n            tasks (List): A list of the tasks to monitor. Should be a list of the results of execute_function.\n            update_interval (bool): Number of seconds the status of tasks are updated.\n            show_time_left (bool): Show the estimated time left to complete tasks using the tqdm progress bar\n            print_statments (bool): Allow printing of status of task queue\n\n        Raises:\n            Exception: If error in the process of executing the tasks\n        \"\"\"\n\n        try:\n            # Wait for the tasks to complete\n            if print_statements:\n                print(\"Tasks submitted to queue. Starting queue...\")\n                print(\"Elapsed time&lt;Estimated time to completion\")\n            with tqdm(total=len(tasks), unit=\"task\") as pbar:\n                while not all(task.ready() for task in tasks):\n                    current_tasks = sum([task.ready() for task in tasks])\n                    pbar.update(current_tasks - pbar.n)\n                    time.sleep(update_interval)\n        except Exception as e:\n            self.log(f\"Error in executing tasks on nodes, {str(e)}\")\n\n        if all(task.ready() for task in tasks):\n            print(\"All tasks completed.\")\n</code></pre>"},{"location":"distributask/#distributask.Distributask.app","title":"<code>app: Celery = Celery('distributask', broker=redis_url, backend=redis_url)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"distributask/#distributask.Distributask.pool","title":"<code>pool: ConnectionPool = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"distributask/#distributask.Distributask.redis_client","title":"<code>redis_client: Redis = self.get_redis_connection()</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"distributask/#distributask.Distributask.registered_functions","title":"<code>registered_functions: dict = {}</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"distributask/#distributask.Distributask.settings","title":"<code>settings = {'HF_REPO_ID': hf_repo_id, 'HF_TOKEN': hf_token, 'VAST_API_KEY': vast_api_key, 'REDIS_HOST': redis_host, 'REDIS_PASSWORD': redis_password, 'REDIS_PORT': redis_port, 'REDIS_USER': redis_username, 'BROKER_POOL_LIMIT': broker_pool_limit}</code>  <code>instance-attribute</code>","text":""},{"location":"distributask/#distributask.Distributask.__del__","title":"<code>__del__()</code>","text":"<p>Destructor to clean up resources.</p> Source code in <code>distributask/distributask.py</code> <pre><code>def __del__(self):\n    \"\"\"Destructor to clean up resources.\"\"\"\n    if self.pool is not None:\n        self.pool.disconnect()\n    if self.redis_client is not None:\n        self.redis_client.close()\n    if self.app is not None:\n        self.app.close()\n</code></pre>"},{"location":"distributask/#distributask.Distributask.__init__","title":"<code>__init__(hf_repo_id=os.getenv('HF_REPO_ID'), hf_token=os.getenv('HF_TOKEN'), vast_api_key=os.getenv('VAST_API_KEY'), redis_host=os.getenv('REDIS_HOST', 'localhost'), redis_password=os.getenv('REDIS_PASSWORD', ''), redis_port=os.getenv('REDIS_PORT', 6379), redis_username=os.getenv('REDIS_USER', 'default'), broker_pool_limit=os.getenv('BROKER_POOL_LIMIT', 1))</code>","text":"<p>Initialize the Distributask object with the provided configuration parameters. Also sets some default settings in Celery and handles cleanup of Celery queue and Redis server on exit.</p> <p>Parameters:</p> Name Type Description Default <code>hf_repo_id</code> <code>str</code> <p>Hugging Face repository ID.</p> <code>getenv('HF_REPO_ID')</code> <code>hf_token</code> <code>str</code> <p>Hugging Face API token.</p> <code>getenv('HF_TOKEN')</code> <code>vast_api_key</code> <code>str</code> <p>Vast.ai API key.</p> <code>getenv('VAST_API_KEY')</code> <code>redis_host</code> <code>str</code> <p>Redis host. Defaults to \"localhost\".</p> <code>getenv('REDIS_HOST', 'localhost')</code> <code>redis_password</code> <code>str</code> <p>Redis password. Defaults to an empty string.</p> <code>getenv('REDIS_PASSWORD', '')</code> <code>redis_port</code> <code>int</code> <p>Redis port. Defaults to 6379.</p> <code>getenv('REDIS_PORT', 6379)</code> <code>redis_username</code> <code>str</code> <p>Redis username. Defaults to \"default\".</p> <code>getenv('REDIS_USER', 'default')</code> <code>broker_pool_limit</code> <code>int</code> <p>Celery broker pool limit. Defaults to 1.</p> <code>getenv('BROKER_POOL_LIMIT', 1)</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If any of the required parameters (hf_repo_id, hf_token, vast_api_key) are not provided.</p> Source code in <code>distributask/distributask.py</code> <pre><code>def __init__(\n    self,\n    hf_repo_id=os.getenv(\"HF_REPO_ID\"),\n    hf_token=os.getenv(\"HF_TOKEN\"),\n    vast_api_key=os.getenv(\"VAST_API_KEY\"),\n    redis_host=os.getenv(\"REDIS_HOST\", \"localhost\"),\n    redis_password=os.getenv(\"REDIS_PASSWORD\", \"\"),\n    redis_port=os.getenv(\"REDIS_PORT\", 6379),\n    redis_username=os.getenv(\"REDIS_USER\", \"default\"),\n    broker_pool_limit=os.getenv(\"BROKER_POOL_LIMIT\", 1),\n) -&gt; None:\n    \"\"\"\n    Initialize the Distributask object with the provided configuration parameters. Also sets some\n    default settings in Celery and handles cleanup of Celery queue and Redis server on exit.\n\n    Args:\n        hf_repo_id (str): Hugging Face repository ID.\n        hf_token (str): Hugging Face API token.\n        vast_api_key (str): Vast.ai API key.\n        redis_host (str): Redis host. Defaults to \"localhost\".\n        redis_password (str): Redis password. Defaults to an empty string.\n        redis_port (int): Redis port. Defaults to 6379.\n        redis_username (str): Redis username. Defaults to \"default\".\n        broker_pool_limit (int): Celery broker pool limit. Defaults to 1.\n\n    Raises:\n        ValueError: If any of the required parameters (hf_repo_id, hf_token, vast_api_key) are not provided.\n    \"\"\"\n    if hf_repo_id is None:\n        raise ValueError(\n            \"HF_REPO_ID is not provided to the Distributask constructor\"\n        )\n\n    if hf_token is None:\n        raise ValueError(\"HF_TOKEN is not provided to the Distributask constructor\")\n\n    if vast_api_key is None:\n        raise ValueError(\n            \"VAST_API_KEY is not provided to the Distributask constructor\"\n        )\n\n    if redis_host == \"localhost\":\n        print(\n            \"WARNING: Using default Redis host 'localhost'. This is not recommended for production use and won't work for distributed rendering.\"\n        )\n\n    self.settings = {\n        \"HF_REPO_ID\": hf_repo_id,\n        \"HF_TOKEN\": hf_token,\n        \"VAST_API_KEY\": vast_api_key,\n        \"REDIS_HOST\": redis_host,\n        \"REDIS_PASSWORD\": redis_password,\n        \"REDIS_PORT\": redis_port,\n        \"REDIS_USER\": redis_username,\n        \"BROKER_POOL_LIMIT\": broker_pool_limit,\n    }\n\n    redis_url = self.get_redis_url()\n    # start Celery app instance\n    self.app = Celery(\"distributask\", broker=redis_url, backend=redis_url)\n    self.app.conf.broker_pool_limit = self.settings[\"BROKER_POOL_LIMIT\"]\n\n    def cleanup_redis():\n        \"\"\"\n        Deletes keys in redis related to Celery tasks and closes the Redis connection on exit\n        \"\"\"\n        patterns = [\"celery-task*\", \"task_status*\"]\n        redis_connection = self.get_redis_connection()\n        for pattern in patterns:\n            for key in redis_connection.scan_iter(match=pattern):\n                redis_connection.delete(key)\n        print(\"Redis server cleared\")\n\n    def cleanup_celery():\n        \"\"\"\n        Clears Celery task queue on exit\n        \"\"\"\n        self.app.control.purge()\n        print(\"Celery queue cleared\")\n\n    # At exit, close Celery instance, delete all previous task info from queue and Redis, and close Redis\n    atexit.register(self.app.close)\n    atexit.register(cleanup_redis)\n    atexit.register(cleanup_celery)\n\n    self.redis_client = self.get_redis_connection()\n\n    # Tasks are acknowledged after they have been executed\n    self.app.conf.task_acks_late = True\n    self.call_function_task = self.app.task(\n        bind=True, name=\"call_function_task\", max_retries=3, default_retry_delay=30\n    )(self.call_function_task)\n</code></pre>"},{"location":"distributask/#distributask.Distributask.call_function_task","title":"<code>call_function_task(func_name, args_json)</code>","text":"<p>Creates Celery task that executes a registered function with provided JSON arguments.</p> <p>Parameters:</p> Name Type Description Default <code>func_name</code> <code>str</code> <p>The name of the registered function to execute.</p> required <code>args_json</code> <code>str</code> <p>JSON string representation of the arguments for the function.</p> required <p>Returns:</p> Name Type Description <code>any</code> <code>any</code> <p>Celery.app.task object, represents result of the registered function</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the function name is not registered.</p> <code>Exception</code> <p>If an error occurs during the execution of the function. The task will retry in this case.</p> Source code in <code>distributask/distributask.py</code> <pre><code>def call_function_task(self, func_name: str, args_json: str) -&gt; any:\n    \"\"\"\n    Creates Celery task that executes a registered function with provided JSON arguments.\n\n    Args:\n        func_name (str): The name of the registered function to execute.\n        args_json (str): JSON string representation of the arguments for the function.\n\n    Returns:\n        any: Celery.app.task object, represents result of the registered function\n\n    Raises:\n        ValueError: If the function name is not registered.\n        Exception: If an error occurs during the execution of the function. The task will retry in this case.\n    \"\"\"\n    try:\n        if func_name not in self.registered_functions:\n            raise ValueError(f\"Function '{func_name}' is not registered.\")\n\n        func = self.registered_functions[func_name]\n        args = json.loads(args_json)\n        result = func(**args)\n        # self.update_function_status(self.call_function_task.request.id, \"success\")\n\n        return result\n    except Exception as e:\n        self.log(f\"Error in call_function_task: {str(e)}\", \"error\")\n</code></pre>"},{"location":"distributask/#distributask.Distributask.create_instance","title":"<code>create_instance(offer_id, image, module_name, env_settings, command)</code>","text":"<p>Create an instance on the Vast.ai platform. Passes in some useful Celery settings by default.</p> <p>Parameters:</p> Name Type Description Default <code>offer_id</code> <code>str</code> <p>The ID of the offer to create the instance from.</p> required <code>image</code> <code>str</code> <p>The image to use for the instance. (example: RaccoonResearch/distributask-test-worker)</p> required <code>module_name</code> <code>str</code> <p>The name of the module to run on the instance, configured to be a docker file (example: distributask.example.worker)</p> required <code>command</code> <code>str</code> <p>Command that initializes celery worker. Has default command with specific settings if not passed in. These settings have</p> required <code>env_settings</code> <code>Dict</code> <p>Used to pass in environment variables to the Vast.ai instance. This is a dictionary with keys of the </p> required <p>Returns:</p> Name Type Description <code>Dict</code> <code>Dict</code> <p>A dictionary representing the created instance.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the Vast.ai API key is not set in the environment.</p> <code>Exception</code> <p>If there is an error while creating the instance.</p> Source code in <code>distributask/distributask.py</code> <pre><code>def create_instance(\n    self, offer_id: str, image: str, module_name: str, env_settings: Dict, command: str\n) -&gt; Dict:\n    \"\"\"\n    Create an instance on the Vast.ai platform. Passes in some useful Celery settings by default.\n\n    Args:\n        offer_id (str): The ID of the offer to create the instance from.\n        image (str): The image to use for the instance. (example: RaccoonResearch/distributask-test-worker)\n        module_name (str): The name of the module to run on the instance, configured to be a docker file (example: distributask.example.worker)\n        command (str): Command that initializes celery worker. Has default command with specific settings if not passed in. These settings have\n        been found to be beneficial to the stability and simplicity of a Distributask run. \n        env_settings (Dict): Used to pass in environment variables to the Vast.ai instance. This is a dictionary with keys of the \n        environment variable name and values of the desired value of the environment variable.\n\n    Returns:\n        Dict: A dictionary representing the created instance.\n\n    Raises:\n        ValueError: If the Vast.ai API key is not set in the environment.\n        Exception: If there is an error while creating the instance.\n    \"\"\"\n    if self.get_env(\"VAST_API_KEY\") is None:\n        self.log(\"VAST_API_KEY is not set in the environment\", \"error\")\n        raise ValueError(\"VAST_API_KEY is not set in the environment\")\n\n    if command is None:\n        command = f\"celery -A {module_name} worker --loglevel=info --concurrency=1 --without-heartbeat --prefetch-multiplier=1\"\n\n    if env_settings is None:\n        env_settings = self.settings\n\n    json_blob = {\n        \"client_id\": \"me\",\n        \"image\": image,\n        \"env\": env_settings,\n        \"disk\": 32,  # Set a non-zero value for disk\n        \"onstart\": f\"export PATH=$PATH:/ &amp;&amp; cd ../ &amp;&amp; {command}\",\n        \"runtype\": \"ssh ssh_proxy\",\n    }\n    url = f\"https://console.vast.ai/api/v0/asks/{offer_id}/?api_key={self.get_env('VAST_API_KEY')}\"\n    headers = {\"Authorization\": f\"Bearer {self.get_env('VAST_API_KEY')}\"}\n    response = requests.put(url, headers=headers, json=json_blob)\n\n    if response.status_code != 200:\n        self.log(f\"Failed to create instance: {response.text}\", \"error\")\n        raise Exception(f\"Failed to create instance: {response.text}\")\n\n    return response.json()\n</code></pre>"},{"location":"distributask/#distributask.Distributask.delete_file","title":"<code>delete_file(repo_id, path_in_repo)</code>","text":"<p>Delete a file from a Hugging Face repository.</p> <p>Parameters:</p> Name Type Description Default <code>repo_id</code> <code>str</code> <p>The ID of the repository.</p> required <code>path_in_repo</code> <code>str</code> <p>The path of the file to delete within the repository.</p> required <p>Raises:</p> Type Description <code>Exception</code> <p>If an error occurs during the deletion process.</p> Source code in <code>distributask/distributask.py</code> <pre><code>def delete_file(self, repo_id: str, path_in_repo: str) -&gt; None:\n    \"\"\"\n    Delete a file from a Hugging Face repository.\n\n    Args:\n        repo_id (str): The ID of the repository.\n        path_in_repo (str): The path of the file to delete within the repository.\n\n    Raises:\n        Exception: If an error occurs during the deletion process.\n\n    \"\"\"\n    hf_token = self.settings.get(\"HF_TOKEN\")\n    api = HfApi(token=hf_token)\n\n    try:\n        api.delete_file(\n            repo_id=repo_id,\n            path_in_repo=path_in_repo,\n            repo_type=\"dataset\",\n            token=hf_token,\n        )\n        self.log(f\"Deleted {path_in_repo} from Hugging Face repo {repo_id}\")\n    except Exception as e:\n        self.log(\n            f\"Failed to delete {path_in_repo} from Hugging Face repo {repo_id}: {e}\",\n            \"error\",\n        )\n</code></pre>"},{"location":"distributask/#distributask.Distributask.destroy_instance","title":"<code>destroy_instance(instance_id)</code>","text":"<p>Destroy an instance on the Vast.ai platform.</p> <p>Parameters:</p> Name Type Description Default <code>instance_id</code> <code>str</code> <p>The ID of the instance to destroy.</p> required <p>Returns:</p> Name Type Description <code>Dict</code> <code>Dict</code> <p>A dictionary representing the result of the destroy operation.</p> Source code in <code>distributask/distributask.py</code> <pre><code>def destroy_instance(self, instance_id: str) -&gt; Dict:\n    \"\"\"\n    Destroy an instance on the Vast.ai platform.\n\n    Args:\n        instance_id (str): The ID of the instance to destroy.\n\n    Returns:\n        Dict: A dictionary representing the result of the destroy operation.\n    \"\"\"\n    api_key = self.get_env(\"VAST_API_KEY\")\n    headers = {\"Authorization\": f\"Bearer {api_key}\"}\n    url = (\n        f\"https://console.vast.ai/api/v0/instances/{instance_id}/?api_key={api_key}\"\n    )\n    response = requests.delete(url, headers=headers)\n    return response\n</code></pre>"},{"location":"distributask/#distributask.Distributask.execute_function","title":"<code>execute_function(func_name, args)</code>","text":"<p>Execute a registered function as a Celery task with provided arguments.</p> <p>Parameters:</p> Name Type Description Default <code>func_name</code> <code>str</code> <p>The name of the function to execute.</p> required <code>args</code> <code>dict</code> <p>Arguments to pass to the function.</p> required <p>Returns:</p> Type Description <code>AsyncResult</code> <p>celery.result.AsyncResult: An object representing the asynchronous result of the task.</p> Source code in <code>distributask/distributask.py</code> <pre><code>def execute_function(self, func_name: str, args: dict) -&gt; Celery.AsyncResult:\n    \"\"\"\n    Execute a registered function as a Celery task with provided arguments.\n\n    Args:\n        func_name (str): The name of the function to execute.\n        args (dict): Arguments to pass to the function.\n\n    Returns:\n        celery.result.AsyncResult: An object representing the asynchronous result of the task.\n    \"\"\"\n    args_json = json.dumps(args)\n    async_result = self.call_function_task.delay(func_name, args_json)\n    return async_result\n</code></pre>"},{"location":"distributask/#distributask.Distributask.file_exists","title":"<code>file_exists(repo_id, path_in_repo)</code>","text":"<p>Check if a file exists in a Hugging Face repository.</p> <p>Parameters:</p> Name Type Description Default <code>repo_id</code> <code>str</code> <p>The ID of the repository.</p> required <code>path_in_repo</code> <code>str</code> <p>The path of the file to check within the repository.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the file exists in the repository, False otherwise.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If an error occurs while checking the existence of the file.</p> Source code in <code>distributask/distributask.py</code> <pre><code>def file_exists(self, repo_id: str, path_in_repo: str) -&gt; bool:\n    \"\"\"\n    Check if a file exists in a Hugging Face repository.\n\n    Args:\n        repo_id (str): The ID of the repository.\n        path_in_repo (str): The path of the file to check within the repository.\n\n    Returns:\n        bool: True if the file exists in the repository, False otherwise.\n\n    Raises:\n        Exception: If an error occurs while checking the existence of the file.\n    \"\"\"\n    hf_token = self.settings.get(\"HF_TOKEN\")\n    api = HfApi(token=hf_token)\n\n    try:\n        repo_files = api.list_repo_files(\n            repo_id=repo_id, repo_type=\"dataset\", token=hf_token\n        )\n        return path_in_repo in repo_files\n    except Exception as e:\n        self.log(\n            f\"Failed to check if {path_in_repo} exists in Hugging Face repo {repo_id}: {e}\",\n            \"error\",\n        )\n        return False\n</code></pre>"},{"location":"distributask/#distributask.Distributask.get_env","title":"<code>get_env(key, default=None)</code>","text":"<p>Retrieve a value from the configuration or .env file, with an optional default if the key is not found.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The key to look for in the settings.</p> required <code>default</code> <code>any</code> <p>The default value to return if the key is not found. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>any</code> <code>any</code> <p>The value from the settings if the key exists, otherwise the default value.</p> Source code in <code>distributask/distributask.py</code> <pre><code>def get_env(self, key: str, default: any = None) -&gt; any:\n    \"\"\"\n    Retrieve a value from the configuration or .env file, with an optional default if the key is not found.\n\n    Args:\n        key (str): The key to look for in the settings.\n        default (any): The default value to return if the key is not found. Defaults to None.\n\n    Returns:\n        any: The value from the settings if the key exists, otherwise the default value.\n    \"\"\"\n    return self.settings.get(key, default)\n</code></pre>"},{"location":"distributask/#distributask.Distributask.get_node_log","title":"<code>get_node_log(node, wait_time=2)</code>","text":"<p>Get the log of the Vast.ai instance that is passed in. Makes an api call to tell the instance to send the log, and another one to actually retrive the log Args:     node (Dict): the node that corresponds to the Vast.ai instance you want the log from     wait_time (int): how long to wait in between the two api calls described above</p> <p>Returns:</p> Name Type Description <code>str</code> <p>the log of the instance requested. If anything else other than a code 200 is received, return None</p> Source code in <code>distributask/distributask.py</code> <pre><code>def get_node_log(self, node: Dict, wait_time: int = 2):\n    \"\"\"\n    Get the log of the Vast.ai instance that is passed in. Makes an api call to tell the instance to send the log,\n    and another one to actually retrive the log\n    Args:\n        node (Dict): the node that corresponds to the Vast.ai instance you want the log from\n        wait_time (int): how long to wait in between the two api calls described above\n\n    Returns:\n        str: the log of the instance requested. If anything else other than a code 200 is received, return None\n    \"\"\"\n    node_id = node[\"instance_id\"]\n    url = f\"https://console.vast.ai/api/v0/instances/request_logs/{node_id}/\"\n\n    payload = {\"tail\": \"1000\"}\n    headers = {\n        \"Accept\": \"application/json\",\n        \"Authorization\": f\"Bearer {self.settings['VAST_API_KEY']}\",\n    }\n\n    response = requests.request(\n        \"PUT\", url, headers=headers, json=payload, timeout=5\n    )\n\n    if response.status_code == 200:\n        log_url = response.json()[\"result_url\"]\n        time.sleep(wait_time)\n        log_response = requests.get(log_url, timeout=5)\n        if log_response.status_code == 200:\n            return log_response\n        else:\n            return None\n    else:\n        return None\n</code></pre>"},{"location":"distributask/#distributask.Distributask.get_redis_connection","title":"<code>get_redis_connection(force_new=False)</code>","text":"<p>Returns Redis connection. If it already exists, returns current connection. If it does not exist, its create a new Redis connection using a connection pool.</p> <p>Parameters:</p> Name Type Description Default <code>force_new</code> <code>bool</code> <p>Force the creation of a new connection if set to True. Defaults to False.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>Redis</code> <code>Redis</code> <p>A Redis connection object.</p> Source code in <code>distributask/distributask.py</code> <pre><code>def get_redis_connection(self, force_new: bool = False) -&gt; Redis:\n    \"\"\"\n    Returns Redis connection. If it already exists, returns current connection.\n    If it does not exist, its create a new Redis connection using a connection pool.\n\n    Args:\n        force_new (bool): Force the creation of a new connection if set to True. Defaults to False.\n\n    Returns:\n        Redis: A Redis connection object.\n    \"\"\"\n    if self.redis_client is not None and not force_new:\n        return self.redis_client\n    else:\n        self.pool = ConnectionPool(host=self.settings[\"REDIS_HOST\"], \n                                   port=self.settings[\"REDIS_PORT\"],\n                                   password=self.settings[\"REDIS_PASSWORD\"], \n                                   max_connections=1)\n        self.redis_client = Redis(connection_pool=self.pool)\n        atexit.register(self.pool.disconnect)\n\n    return self.redis_client\n</code></pre>"},{"location":"distributask/#distributask.Distributask.get_redis_url","title":"<code>get_redis_url()</code>","text":"<p>Construct a Redis URL from the configuration settings.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>A Redis URL string.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If any required Redis connection parameter is missing.</p> Source code in <code>distributask/distributask.py</code> <pre><code>def get_redis_url(self) -&gt; str:\n    \"\"\"\n    Construct a Redis URL from the configuration settings.\n\n    Returns:\n        str: A Redis URL string.\n\n    Raises:\n        ValueError: If any required Redis connection parameter is missing.\n    \"\"\"\n    host = self.settings[\"REDIS_HOST\"]\n    password = self.settings[\"REDIS_PASSWORD\"]\n    port = self.settings[\"REDIS_PORT\"]\n    username = self.settings[\"REDIS_USER\"]\n\n    if None in [host, password, port, username]:\n        raise ValueError(\"Missing required Redis configuration values\")\n\n    redis_url = f\"redis://{username}:{password}@{host}:{port}\"\n    return redis_url\n</code></pre>"},{"location":"distributask/#distributask.Distributask.get_settings","title":"<code>get_settings()</code>","text":"<p>Return settings of distributask instance.</p> Source code in <code>distributask/distributask.py</code> <pre><code>def get_settings(self) -&gt; str:\n    \"\"\"\n    Return settings of distributask instance.\n    \"\"\"\n    return self.settings\n</code></pre>"},{"location":"distributask/#distributask.Distributask.initialize_dataset","title":"<code>initialize_dataset(**kwargs)</code>","text":"<p>Initialize a Hugging Face repository if it doesn't exist. Reads Hugging Face info from config or .env</p> <p>Parameters:</p> Name Type Description Default <code>kwargs</code> <p>kwargs that can be passed into the HfApi.create_repo function.</p> <code>{}</code> <p>Raises:</p> Type Description <code>HTTPError</code> <p>If repo cannot be created due to connection error other than repo not existing</p> Source code in <code>distributask/distributask.py</code> <pre><code>def initialize_dataset(self, **kwargs) -&gt; None:\n    \"\"\"\n    Initialize a Hugging Face repository if it doesn't exist. Reads Hugging Face info from config or .env\n\n    Args:\n        kwargs: kwargs that can be passed into the HfApi.create_repo function.\n\n    Raises:\n        HTTPError: If repo cannot be created due to connection error other than repo not existing\n    \"\"\"\n    repo_id = self.settings.get(\"HF_REPO_ID\")\n    hf_token = self.settings.get(\"HF_TOKEN\")\n    api = HfApi(token=hf_token)\n\n    # creates new repo if desired repo is not found\n    try:\n        repo_info = api.repo_info(repo_id=repo_id, repo_type=\"dataset\", timeout=30)\n    except HTTPError as e:\n        if e.response.status_code == 404:\n            self.log(\n                f\"Repository {repo_id} does not exist. Creating a new repository.\",\n                \"warn\",\n            )\n            api.create_repo(\n                repo_id=repo_id, token=hf_token, repo_type=\"dataset\", **kwargs\n            )\n        else:\n            raise e\n\n    # Create config.json file\n    config = {\n        \"data_loader_name\": \"custom\",\n        \"data_loader_kwargs\": {\n            \"path\": repo_id,\n            \"format\": \"files\",\n            \"fields\": [\"file_path\", \"text\"],\n        },\n    }\n\n    # apply config.json to created repo\n    with tempfile.TemporaryDirectory() as temp_dir:\n        with Repository(\n            local_dir=temp_dir,\n            clone_from=repo_id,\n            repo_type=\"dataset\",\n            use_auth_token=hf_token,\n        ).commit(commit_message=\"Add config.json\"):\n            with open(os.path.join(temp_dir, \"config.json\"), \"w\") as f:\n                json.dump(config, f, indent=2)\n\n    self.log(f\"Initialized repository {repo_id}.\")\n</code></pre>"},{"location":"distributask/#distributask.Distributask.list_files","title":"<code>list_files(repo_id)</code>","text":"<p>Get a list of files from a Hugging Face repository.</p> <p>Parameters:</p> Name Type Description Default <code>repo_id</code> <code>str</code> <p>The ID of the repository.</p> required <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>A list of file paths in the repository.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If an error occurs while retrieving the list of files.</p> Source code in <code>distributask/distributask.py</code> <pre><code>def list_files(self, repo_id: str) -&gt; list:\n    \"\"\"\n    Get a list of files from a Hugging Face repository.\n\n    Args:\n        repo_id (str): The ID of the repository.\n\n    Returns:\n        list: A list of file paths in the repository.\n\n    Raises:\n        Exception: If an error occurs while retrieving the list of files.\n    \"\"\"\n    hf_token = self.settings.get(\"HF_TOKEN\")\n    api = HfApi(token=hf_token)\n\n    try:\n        repo_files = api.list_repo_files(\n            repo_id=repo_id, repo_type=\"dataset\", token=hf_token\n        )\n        return repo_files\n    except Exception as e:\n        self.log(\n            f\"Failed to get the list of files from Hugging Face repo {repo_id}: {e}\",\n            \"error\",\n        )\n        return []\n</code></pre>"},{"location":"distributask/#distributask.Distributask.log","title":"<code>log(message, level='info')</code>","text":"<p>Log a message with the specified level.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>The message to log.</p> required <code>level</code> <code>str</code> <p>The logging level. Defaults to \"info\".</p> <code>'info'</code> Source code in <code>distributask/distributask.py</code> <pre><code>def log(self, message: str, level: str = \"info\") -&gt; None:\n    \"\"\"\n    Log a message with the specified level.\n\n    Args:\n        message (str): The message to log.\n        level (str): The logging level. Defaults to \"info\".\n    \"\"\"\n    logger = get_task_logger(__name__)\n    getattr(logger, level)(message)\n</code></pre>"},{"location":"distributask/#distributask.Distributask.monitor_tasks","title":"<code>monitor_tasks(tasks, update_interval=1, show_time_left=True, print_statements=True)</code>","text":"<p>Monitor the status of the tasks on the Vast.ai nodes.</p> <p>Parameters:</p> Name Type Description Default <code>tasks</code> <code>List</code> <p>A list of the tasks to monitor. Should be a list of the results of execute_function.</p> required <code>update_interval</code> <code>bool</code> <p>Number of seconds the status of tasks are updated.</p> <code>1</code> <code>show_time_left</code> <code>bool</code> <p>Show the estimated time left to complete tasks using the tqdm progress bar</p> <code>True</code> <code>print_statments</code> <code>bool</code> <p>Allow printing of status of task queue</p> required <p>Raises:</p> Type Description <code>Exception</code> <p>If error in the process of executing the tasks</p> Source code in <code>distributask/distributask.py</code> <pre><code>def monitor_tasks(\n    self, tasks, update_interval=1, show_time_left=True, print_statements=True\n):\n    \"\"\"\n    Monitor the status of the tasks on the Vast.ai nodes.\n\n    Args:\n        tasks (List): A list of the tasks to monitor. Should be a list of the results of execute_function.\n        update_interval (bool): Number of seconds the status of tasks are updated.\n        show_time_left (bool): Show the estimated time left to complete tasks using the tqdm progress bar\n        print_statments (bool): Allow printing of status of task queue\n\n    Raises:\n        Exception: If error in the process of executing the tasks\n    \"\"\"\n\n    try:\n        # Wait for the tasks to complete\n        if print_statements:\n            print(\"Tasks submitted to queue. Starting queue...\")\n            print(\"Elapsed time&lt;Estimated time to completion\")\n        with tqdm(total=len(tasks), unit=\"task\") as pbar:\n            while not all(task.ready() for task in tasks):\n                current_tasks = sum([task.ready() for task in tasks])\n                pbar.update(current_tasks - pbar.n)\n                time.sleep(update_interval)\n    except Exception as e:\n        self.log(f\"Error in executing tasks on nodes, {str(e)}\")\n\n    if all(task.ready() for task in tasks):\n        print(\"All tasks completed.\")\n</code></pre>"},{"location":"distributask/#distributask.Distributask.register_function","title":"<code>register_function(func)</code>","text":"<p>Decorator to register a function so that it can be invoked as a Celery task.</p> <p>Parameters:</p> Name Type Description Default <code>func</code> <code>callable</code> <p>The function to register.</p> required <p>Returns:</p> Name Type Description <code>callable</code> <code>callable</code> <p>The original function, now registered as a callable task.</p> Source code in <code>distributask/distributask.py</code> <pre><code>def register_function(self, func: callable) -&gt; callable:\n    \"\"\"\n    Decorator to register a function so that it can be invoked as a Celery task.\n\n    Args:\n        func (callable): The function to register.\n\n    Returns:\n        callable: The original function, now registered as a callable task.\n    \"\"\"\n    self.registered_functions[func.__name__] = func\n    return func\n</code></pre>"},{"location":"distributask/#distributask.Distributask.rent_nodes","title":"<code>rent_nodes(max_price, max_nodes, image, module_name, env_settings=None, command=None)</code>","text":"<p>Rent nodes as an instance on the Vast.ai platform.</p> <p>Parameters:</p> Name Type Description Default <code>max_price</code> <code>float</code> <p>The maximum price per hour for the nodes.</p> required <code>max_nodes</code> <code>int</code> <p>The maximum number of nodes to rent.</p> required <code>image</code> <code>str</code> <p>The image to use for the nodes.</p> required <code>module_name</code> <code>str</code> <p>The name of the module to run on the nodes.</p> required <p>Returns:</p> Type Description <code>List[Dict]</code> <p>List[Dict]: A list of dictionaries representing the rented nodes. If error is encountered</p> <code>List[Dict]</code> <p>trying to rent, it will retry every 5 seconds.</p> Source code in <code>distributask/distributask.py</code> <pre><code>def rent_nodes(\n    self,\n    max_price: float,\n    max_nodes: int,\n    image: str,\n    module_name: str,\n    env_settings: Dict = None,\n    command: str = None,\n) -&gt; List[Dict]:\n    \"\"\"\n    Rent nodes as an instance on the Vast.ai platform.\n\n    Args:\n        max_price (float): The maximum price per hour for the nodes.\n        max_nodes (int): The maximum number of nodes to rent.\n        image (str): The image to use for the nodes.\n        module_name (str): The name of the module to run on the nodes.\n\n    Returns:\n        List[Dict]: A list of dictionaries representing the rented nodes. If error is encountered\n        trying to rent, it will retry every 5 seconds.\n    \"\"\"\n    rented_nodes: List[Dict] = []\n    while len(rented_nodes) &lt; max_nodes:\n        search_retries = 10\n        while search_retries &gt; 0:\n            try:\n                offers = self.search_offers(max_price)\n                break\n            except Exception as e:\n                self.log(\n                    f\"Error searching for offers: {str(e)} - retrying in 5 seconds...\",\n                    \"error\",\n                )\n                search_retries -= 1\n                # sleep for 10 seconds before retrying\n                time.sleep(10)\n                continue\n\n        offers = sorted(\n            offers, key=lambda offer: offer[\"dph_total\"]\n        )  # Sort offers by price, lowest to highest\n        for offer in offers:\n            time.sleep(5)\n            if len(rented_nodes) &gt;= max_nodes:\n                break\n            try:\n                instance = self.create_instance(\n                    offer[\"id\"], image, module_name, env_settings=env_settings, command=command\n                )\n                rented_nodes.append(\n                    {\n                        \"offer_id\": offer[\"id\"],\n                        \"instance_id\": instance[\"new_contract\"],\n                    }\n                )\n            except Exception as e:\n                self.log(\n                    f\"Error renting node: {str(e)} - searching for new offers\",\n                    \"error\",\n                )\n                break  # Break out of the current offer iteration\n        else:\n            # If the loop completes without breaking, all offers have been tried\n            self.log(\"No more offers available - stopping node rental\", \"warning\")\n            break\n\n    atexit.register(self.terminate_nodes, rented_nodes)\n    return rented_nodes\n</code></pre>"},{"location":"distributask/#distributask.Distributask.search_offers","title":"<code>search_offers(max_price)</code>","text":"<p>Search for available offers to rent a node as an instance on the Vast.ai platform.</p> <p>Parameters:</p> Name Type Description Default <code>max_price</code> <code>float</code> <p>The maximum price per hour for the instance.</p> required <p>Returns:</p> Type Description <code>List[Dict]</code> <p>List[Dict]: A list of dictionaries representing the available offers.</p> <p>Raises:</p> Type Description <code>RequestException</code> <p>If there is an error while making the API request.</p> Source code in <code>distributask/distributask.py</code> <pre><code>def search_offers(self, max_price: float) -&gt; List[Dict]:\n    \"\"\"\n    Search for available offers to rent a node as an instance on the Vast.ai platform.\n\n    Args:\n        max_price (float): The maximum price per hour for the instance.\n\n    Returns:\n        List[Dict]: A list of dictionaries representing the available offers.\n\n    Raises:\n        requests.exceptions.RequestException: If there is an error while making the API request.\n    \"\"\"\n    api_key = self.get_env(\"VAST_API_KEY\")\n    base_url = \"https://console.vast.ai/api/v0/bundles/\"\n    headers = {\n        \"Accept\": \"application/json\",\n        \"Content-Type\": \"application/json\",\n        \"Authorization\": f\"Bearer {api_key}\",\n    }\n    url = (\n        base_url\n        + '?q={\"gpu_ram\":\"&gt;=4\",\"rentable\":{\"eq\":true},\"dph_total\":{\"lte\":'\n        + str(max_price)\n        + '},\"sort_option\":{\"0\":[\"dph_total\",\"asc\"],\"1\":[\"total_flops\",\"asc\"]}}'\n    )\n\n    try:\n        response = requests.get(url, headers=headers)\n        response.raise_for_status()\n        json_response = response.json()\n        return json_response[\"offers\"]\n\n    except requests.exceptions.RequestException as e:\n        self.log(\n            f\"Error: {e}\\nResponse: {response.text if response else 'No response'}\"\n        )\n        raise\n</code></pre>"},{"location":"distributask/#distributask.Distributask.terminate_nodes","title":"<code>terminate_nodes(nodes)</code>","text":"<p>Terminate the instances of rented nodes on Vast.ai.</p> <p>Parameters:</p> Name Type Description Default <code>nodes</code> <code>List[Dict]</code> <p>A list of dictionaries representing the rented nodes.</p> required <p>Raises:</p> Type Description <code>Exception</code> <p>If error in destroying instances.</p> Source code in <code>distributask/distributask.py</code> <pre><code>def terminate_nodes(self, nodes: List[Dict]) -&gt; None:\n    \"\"\"\n    Terminate the instances of rented nodes on Vast.ai.\n\n    Args:\n        nodes (List[Dict]): A list of dictionaries representing the rented nodes.\n\n    Raises:\n        Exception: If error in destroying instances.\n    \"\"\"\n    print(\"Terminating nodes...\")\n    for node in nodes:\n        time.sleep(1)\n        try:\n            response = self.destroy_instance(node[\"instance_id\"])\n            if response.status_code != 200:\n                time.sleep(5)\n                self.destroy_instance(node[\"instance_id\"])\n        except Exception as e:\n            self.log(\n                f\"Error terminating node: {node['instance_id']}, {str(e)}\", \"error\"\n            )\n</code></pre>"},{"location":"distributask/#distributask.Distributask.update_function_status","title":"<code>update_function_status(task_id, status)</code>","text":"<p>Update the status of a function task as a new Redis key.</p> <p>Parameters:</p> Name Type Description Default <code>task_id</code> <code>str</code> <p>The ID of the task.</p> required <code>status</code> <code>str</code> <p>The new status to set.</p> required Source code in <code>distributask/distributask.py</code> <pre><code>def update_function_status(self, task_id: str, status: str) -&gt; None:\n    \"\"\"\n    Update the status of a function task as a new Redis key.\n\n    Args:\n        task_id (str): The ID of the task.\n        status (str): The new status to set.\n    \"\"\"\n    redis_client = self.get_redis_connection()\n    redis_client.set(f\"task_status:{task_id}\", status)\n</code></pre>"},{"location":"distributask/#distributask.Distributask.upload_directory","title":"<code>upload_directory(dir_path)</code>","text":"<p>Upload a directory to a Hugging Face repository. Can be used to reduce frequency of Hugging Face API calls if you are rate limited while using the upload_file function.</p> <p>Parameters:</p> Name Type Description Default <code>dir_path</code> <code>str</code> <p>The path of the directory to upload.</p> required <p>Raises:</p> Type Description <code>Exception</code> <p>If an error occurs during the upload process.</p> Source code in <code>distributask/distributask.py</code> <pre><code>def upload_directory(self, dir_path: str) -&gt; None:\n    \"\"\"\n    Upload a directory to a Hugging Face repository. Can be used to reduce frequency of Hugging Face API\n    calls if you are rate limited while using the upload_file function.\n\n    Args:\n        dir_path (str): The path of the directory to upload.\n\n    Raises:\n        Exception: If an error occurs during the upload process.\n\n    \"\"\"\n    hf_token = self.settings.get(\"HF_TOKEN\")\n    repo_id = self.settings.get(\"HF_REPO_ID\")\n\n    try:\n        self.log(f\"Uploading {dir_path} to Hugging Face repo {repo_id}\")\n\n        api = HfApi(token=hf_token)\n        api.upload_folder(\n            folder_path=dir_path,\n            repo_id=repo_id,\n            repo_type=\"dataset\",\n        )\n        self.log(f\"Uploaded {dir_path} to Hugging Face repo {repo_id}\")\n    except Exception as e:\n        self.log(\n            f\"Failed to upload {dir_path} to Hugging Face repo {repo_id}: {e}\",\n            \"error\",\n        )\n</code></pre>"},{"location":"distributask/#distributask.Distributask.upload_file","title":"<code>upload_file(file_path)</code>","text":"<p>Upload a file to a Hugging Face repository.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>str</code> <p>The path of the file to upload.</p> required <p>Raises:</p> Type Description <code>Exception</code> <p>If an error occurs during the upload process.</p> Source code in <code>distributask/distributask.py</code> <pre><code>def upload_file(self, file_path: str) -&gt; None:\n    \"\"\"\n    Upload a file to a Hugging Face repository.\n\n    Args:\n        file_path (str): The path of the file to upload.\n\n    Raises:\n        Exception: If an error occurs during the upload process.\n\n    \"\"\"\n    hf_token = self.settings.get(\"HF_TOKEN\")\n    repo_id = self.settings.get(\"HF_REPO_ID\")\n\n    api = HfApi(token=hf_token)\n\n    try:\n        self.log(f\"Uploading {file_path} to Hugging Face repo {repo_id}\")\n        api.upload_file(\n            path_or_fileobj=file_path,\n            path_in_repo=os.path.basename(file_path),\n            repo_id=repo_id,\n            token=hf_token,\n            repo_type=\"dataset\",\n        )\n        self.log(f\"Uploaded {file_path} to Hugging Face repo {repo_id}\")\n    except Exception as e:\n        self.log(\n            f\"Failed to upload {file_path} to Hugging Face repo {repo_id}: {e}\",\n            \"error\",\n        )\n</code></pre>"},{"location":"getting_started/","title":"Getting Started","text":"<p>Below are instructions to get distributask running on your machine. Please read through the rest of the documentation for more detailed information.</p>"},{"location":"getting_started/#installation","title":"Installation","text":"<pre><code>pip install distributask\n</code></pre>"},{"location":"getting_started/#development","title":"Development","text":""},{"location":"getting_started/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.8 or newer (tested on Python 3.11)</li> <li>Redis server</li> <li>Vast.ai API key</li> <li>HuggingFace API key</li> </ul>"},{"location":"getting_started/#setup","title":"Setup","text":"<p>Clone the repository and navigate to the project directory:</p> <pre><code>git clone https://github.com/RaccoonResearch/Distributask.git\ncd Distributask\n</code></pre> <p>Install the required packages:</p> <pre><code>pip install -r requirements.txt\n</code></pre> <p>Install the distributask package:</p> <pre><code>python setup.py install\n</code></pre>"},{"location":"getting_started/#configuration","title":"Configuration","text":"<p>Create a <code>.env</code> file in the root directory of your project or set environment variables to match your setup:</p> <pre><code>REDIS_HOST=redis_host\nREDIS_PORT=redis_port\nREDIS_USER=redis_user\nREDIS_PASSWORD=redis_password\nVAST_API_KEY=your_vastai_api_key\nHF_TOKEN=your_huggingface_token\nHF_REPO_ID=your_huggingface_repo\nBROKER_POOL_LIMIT=broker_pool_limit\n</code></pre>"},{"location":"getting_started/#running-an-example-task","title":"Running an Example Task","text":"<p>To run an example task and see distributask in action, you can execute the example script provided in the project:</p> <pre><code># Run an example task locally\npython -m distributask.example.local\n\n# Run an example task on Vast.ai (\"kitchen sink\" example)\npython -m distributask.example.distributed\n</code></pre>"},{"location":"getting_started/#command-options","title":"Command Options","text":"<p>Below are options you can pass into your distributask example run.</p> <ul> <li><code>--max_price</code> is the max price (in $/hour) a node can be be rented for.</li> <li><code>--max_nodes</code> is the max number of vast.ai nodes that can be rented.</li> <li><code>--docker_image</code> is the name of the docker image to load to the vast.ai node.</li> <li><code>--module_name</code> is the name of the celery worker</li> <li><code>--number_of_tasks</code> is the number of example tasks that will be added to the queue and done by the workers.</li> </ul>"},{"location":"more_info/","title":"Summary of most relevant functions","text":""},{"location":"more_info/#settings-environment-and-help","title":"Settings, Environment, and Help","text":"<ul> <li><code>create_from_config()</code> - creates Distribtask instance using environment variables</li> <li><code>get_env(key)</code> - gets value from .env</li> <li><code>get_settings(key)</code> - gets value from settings dictionary</li> </ul>"},{"location":"more_info/#celery-tasks","title":"Celery tasks","text":"<ul> <li><code>register_function(func)</code> - registers function to be task for worker</li> <li><code>execute_function(func_name, args)</code> - creates Celery task using registered function</li> </ul>"},{"location":"more_info/#redis-server","title":"Redis server","text":"<ul> <li><code>get_redis_url()</code> - gets Redis host url </li> <li><code>get_redis_connection()</code> - gets Redis connection instance</li> </ul>"},{"location":"more_info/#worker-management-via-vastai-api","title":"Worker management via Vast.ai API","text":"<ul> <li><code>search_offers(max_price)</code> - searches for available instances on Vast.ai</li> <li><code>rent_nodes(max_price, max_nodes, image, module_name, command)</code> - rents nodes using Vast.ai instance</li> <li><code>terminate_nodes(node_id_lists)</code> - terminates Vast.ai instance</li> </ul>"},{"location":"more_info/#huggingface-repositories-and-uploading","title":"HuggingFace repositories and uploading","text":"<ul> <li><code>initialize_dataset()</code> - intializes dataset repo on HuggingFace</li> <li><code>upload_file(path_to_file)</code> - uploads file to Huggingface</li> <li><code>upload_directory(path_to_directory)</code> - uploads folder to Huggingface repo</li> <li><code>delete_file(path_to_file)</code> - deletes file on HuggingFace repo</li> </ul>"},{"location":"more_info/#visit-the-distributask-class-page-for-full-detailed-documentation-of-the-distributask-class","title":"Visit the Distributask Class page for full, detailed documentation of the distributask class.","text":""},{"location":"more_info/#docker-setup","title":"Docker Setup","text":"<p>Distributask uses a Docker image to transfer the environment and neccessary files to the Vast.ai nodes. In your implementation using Distributask, you can use the Docker file in the Distributask repository as a base for your own Docker file. If you do this, be sure to add Distributask to the list of packages to be installed on your Docker file.</p>"},{"location":"more_info/#important-packages","title":"Important Packages","text":"<p>Visit the websites of these wonderful packages to learn more about how they work and how to use them.</p> <p>Celery: <code>https://docs.celeryq.dev/en/stable/</code>  Redis: <code>https://redis.io/docs/latest/</code> Hugging Face: <code>https://huggingface.co/docs/huggingface_hub/en/guides/upload</code> </p>"}]}